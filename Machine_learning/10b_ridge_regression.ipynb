{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "Ridge regression is a type of regression analysis that performs L2 regularization, which adds a penalty term to the loss function to prevent overfitting. The penalty term is proportional to the magnitude of the model coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.8 1.4]\n",
      "Intercept: 4.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "# Target values\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "\n",
    "# Ridge Regression Model\n",
    "ridge_reg = Ridge(alpha=1.0)  # alpha is the equivalent of lambda in the formula\n",
    "ridge_reg.fit(X, y)\n",
    "\n",
    "# Coefficients\n",
    "print(\"Coefficients:\", ridge_reg.coef_)\n",
    "# Intercept\n",
    "print(\"Intercept:\", ridge_reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression vs Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Load Titanic dataset\n",
    "df = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sufwa\\AppData\\Local\\Temp\\ipykernel_14740\\2343086075.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['age'].fillna(df['age'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Selecting a subset of columns for simplicity\n",
    "columns_to_use = ['survived', 'pclass', 'sex', 'age', 'fare']\n",
    "df = df[columns_to_use]\n",
    "\n",
    "# Handling missing values\n",
    "df['age'].fillna(df['age'].median(), inplace=True)\n",
    "\n",
    "# Define feature and target variable\n",
    "X = df.drop('survived', axis=1)\n",
    "y = df['survived']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline for OneHotEncoding and model\n",
    "categorical_features = ['sex']\n",
    "numerical_features = ['pclass', 'age', 'fare']\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)])\n",
    "\n",
    "# Linear Regression Pipeline\n",
    "lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('regressor', LinearRegression())])\n",
    "\n",
    "# Ridge Regression Pipeline\n",
    "ridge_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('regressor', Ridge(alpha=1.0))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and Evaluate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.13684268526287452\n",
      "Ridge Regression MSE: 0.13686022744784476\n",
      "Linear Regression R2: 0.4223219395905452\n",
      "Ridge Regression R2: 0.42224788568426963\n",
      "Linear Regression MAE: 0.28882295584163387\n",
      "Ridge Regression MAE: 0.2892312673071361\n",
      "Linear Regression MAPE: 697272156502681.8\n",
      "Ridge Regression MAPE: 698032476179648.6\n",
      "Linear Regression RMSE: 0.3699225395442599\n",
      "Ridge Regression RMSE: 0.3699462494036732\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Linear Regression\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "lr_pred = lr_pipeline.predict(X_test)\n",
    "lr_mse = mean_squared_error(y_test, lr_pred)\n",
    "lr_r2 = r2_score(y_test, lr_pred)\n",
    "lr_mae = mean_absolute_error(y_test, lr_pred)\n",
    "lr_mape = mean_absolute_percentage_error(y_test, lr_pred)\n",
    "lr_rmse = np.sqrt(lr_mse)\n",
    "\n",
    "# Train and evaluate Ridge Regression\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "ridge_pred = ridge_pipeline.predict(X_test)\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "ridhe_r2 = r2_score(y_test, ridge_pred)\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_pred)\n",
    "ridge_mape = mean_absolute_percentage_error(y_test, ridge_pred)\n",
    "ridge_rmse = np.sqrt(ridge_mse)\n",
    "\n",
    "print(\"Linear Regression MSE:\", lr_mse)\n",
    "print(\"Ridge Regression MSE:\", ridge_mse)\n",
    "\n",
    "print(\"Linear Regression R2:\", lr_r2)\n",
    "print(\"Ridge Regression R2:\", ridhe_r2)\n",
    "\n",
    "print(\"Linear Regression MAE:\", lr_mae)\n",
    "print(\"Ridge Regression MAE:\", ridge_mae)\n",
    "\n",
    "print(\"Linear Regression MAPE:\", lr_mape)\n",
    "print(\"Ridge Regression MAPE:\", ridge_mape)\n",
    "\n",
    "print(\"Linear Regression RMSE:\", lr_rmse)\n",
    "print(\"Ridge Regression RMSE:\", ridge_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
